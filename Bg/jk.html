<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<title>Mochi.py Remote</title>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js"></script>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">

<style>
:root{
--bg:#0d1117;--panel:#161b22;--border:#30363d;
--accent:#58a6ff;--string:#a5d6ff;
--keyword:#ff7b72;--success:#3fb950;--text:#c9d1d9;
}
body{margin:0;background:var(--bg);color:var(--text);
font-family:'JetBrains Mono',monospace;height:100vh;display:flex;flex-direction:column}
.terminal-header{background:var(--panel);padding:10px 15px;
border-bottom:1px solid var(--border);display:flex;justify-content:space-between}
.status-badge{padding:3px 10px;border-radius:4px;background:#444}
.main-container{flex:1;display:flex;justify-content:center;align-items:center}
.video-wrapper{width:100%;max-width:640px;aspect-ratio:4/3;
border:2px solid var(--border);border-radius:8px;position:relative;overflow:hidden}
video,canvas{position:absolute;width:100%;height:100%;object-fit:cover;transform:scaleX(-1)}
.data-overlay{position:absolute;top:10px;left:10px;
background:rgba(0,0,0,.7);padding:8px;font-size:12px;border-left:3px solid var(--accent)}
.gesture-popup{position:absolute;bottom:20px;left:50%;
transform:translateX(-50%);padding:10px 20px;
border:1px solid var(--accent);border-radius:6px;
font-size:18px;font-weight:bold;opacity:0;transition:.3s}
.controls{display:flex;gap:10px;padding:10px}
input,button{font-family:inherit;padding:8px;border-radius:4px}
input{flex:1;background:var(--panel);color:white;border:1px solid var(--border)}
button{background:var(--accent);border:none;font-weight:bold;cursor:pointer}
.console-logs{height:150px;background:var(--panel);
border-top:1px solid var(--border);padding:8px;overflow:auto;font-size:12px}
.log-info{color:var(--string)} .log-success{color:var(--success)}
.log-warn{color:var(--keyword)}
</style>
</head>

<body>

<div class="terminal-header">
<span>root@mochi-ai:~/vision $</span>
<span id="sys" class="status-badge">INIT</span>
</div>

<div class="main-container">
<div class="video-wrapper">
<video id="cam" autoplay playsinline></video>
<canvas id="cvs"></canvas>
<div class="data-overlay">
FPS:<span id="fps">0</span><br>
CONF:<span id="conf">0.00</span><br>
MODE:<span id="mode">IDLE</span>
</div>
<div id="popup" class="gesture-popup">NONE</div>
</div>
</div>

<div class="controls">
<input id="ip" placeholder="192.168.x.x">
<button id="start">RUN</button>
</div>

<div class="console-logs" id="log"></div>

<script type="module">
import {HandLandmarker,FilesetResolver} from
"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

const cam=document.getElementById("cam"),
cvs=document.getElementById("cvs"),
ctx=cvs.getContext("2d"),
fpsEl=document.getElementById("fps"),
confEl=document.getElementById("conf"),
modeEl=document.getElementById("mode"),
popup=document.getElementById("popup"),
logBox=document.getElementById("log"),
sys=document.getElementById("sys");

function log(t,c="log-info"){
const d=document.createElement("div");
d.className=c;d.textContent="> "+t;logBox.appendChild(d);
logBox.scrollTop=logBox.scrollHeight;
}

let landmarker,lastTime=0,lastGesture=null,cooldown=0;

// ---------- SMOOTHING (PYTHON STYLE) ----------
class Smooth{
constructor(a=0.7){this.a=a;this.p=null;}
apply(l){
if(!this.p){this.p=l.map(x=>({...x}));return l;}
this.p=l.map((x,i)=>({
x:this.a*x.x+(1-this.a)*this.p[i].x,
y:this.a*x.y+(1-this.a)*this.p[i].y,
z:this.a*x.z+(1-this.a)*this.p[i].z
}));
return this.p;
}}
const smoother=new Smooth();

// ---------- MATH ----------
const dist=(a,b)=>Math.hypot(a.x-b.x,a.y-b.y);
const angle=(a,b,c)=>{
const ab=[a.x-b.x,a.y-b.y],cb=[c.x-b.x,c.y-b.y];
return Math.acos((ab[0]*cb[0]+ab[1]*cb[1])/
(Math.hypot(...ab)*Math.hypot(...cb)))*180/Math.PI;
};

function fingerOpen(lm,tip,pip,mcp){
return angle(lm[mcp],lm[pip],lm[tip])>160;
}

// ---------- REAL GESTURE ENGINE ----------
let buffer=[];
function detect(lm){
const idx=fingerOpen(lm,8,6,5);
const mid=fingerOpen(lm,12,10,9);
const ring=fingerOpen(lm,16,14,13);
const pink=fingerOpen(lm,20,18,17);
const thumb=dist(lm[4],lm[2])>0.06;

if(idx&&thumb&&!mid&&!ring&&!pink) return "GUN";
if(idx&&pink&&thumb&&!mid&&!ring) return "ILY";
return null;
}

function temporal(g){
buffer.push(g);
if(buffer.length>12) buffer.shift();
return buffer.filter(x=>x===g).length>=8;
}

function fire(name){
if(Date.now()<cooldown) return;
cooldown=Date.now()+4000;
modeEl.textContent=name;
popup.textContent=name+" CONFIRMED";
popup.style.opacity=1;
setTimeout(()=>popup.style.opacity=0,1000);
send(name==="GUN"?"angry":"love");
}

// ---------- DRAW ----------
function draw(lm){
ctx.clearRect(0,0,cvs.width,cvs.height);
ctx.strokeStyle="#00ff00";ctx.fillStyle="#00ff00";
for(const c of HandLandmarker.HAND_CONNECTIONS){
ctx.beginPath();
ctx.moveTo(lm[c.start].x*cvs.width,lm[c.start].y*cvs.height);
ctx.lineTo(lm[c.end].x*cvs.width,lm[c.end].y*cvs.height);
ctx.stroke();
}
lm.forEach(p=>{
ctx.beginPath();
ctx.arc(p.x*cvs.width,p.y*cvs.height,3,0,6.28);
ctx.fill();
});
}

// ---------- LOOP ----------
async function loop(){
const now=performance.now();
fpsEl.textContent=Math.round(1000/(now-lastTime||1));
lastTime=now;

const r=landmarker.detectForVideo(cam,now);
if(r.landmarks?.length){
confEl.textContent=r.handednesses[0][0].score.toFixed(2);
const lm=smoother.apply(r.landmarks[0]);
draw(lm);
const g=detect(lm);
if(g && temporal(g) && g!==lastGesture){
lastGesture=g;fire(g);
}
}else{
modeEl.textContent="IDLE";confEl.textContent="0.00";
}
requestAnimationFrame(loop);
}

// ---------- NETWORK ----------
function send(ep){
const ip=document.getElementById("ip").value;
fetch(`http://${ip}/api/${ep}`)
.then(()=>log("ACTION SENT","log-success"))
.catch(()=>log("NETWORK ERROR","log-warn"));
}

// ---------- START ----------
async function start(){
const vision=await FilesetResolver.forVisionTasks(
"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
landmarker=await HandLandmarker.createFromOptions(vision,{
baseOptions:{modelAssetPath:
"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"},
runningMode:"VIDEO",numHands:1});
const s=await navigator.mediaDevices.getUserMedia({video:{width:640,height:480}});
cam.srcObject=s;cam.onloadeddata=()=>loop();
sys.textContent="READY";sys.style.background="#238636";
log("SYSTEM READY","log-success");
}
document.getElementById("start").onclick=start;
</script>
</body>
</html>
